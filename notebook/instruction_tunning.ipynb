{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873f9cd6-5eda-4122-bf82-d737599dd602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340814a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 52002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"../data/alpaca_data.json\"\n",
    "# url = (\n",
    "# \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "# \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "# )\n",
    "url = (\"https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json\")\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabed46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78806cf7-1251-4f7b-93af-3ee91fb895cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': 'Describe the flavor profile of the following type of cuisine', 'input': 'Japanese', 'output': 'Japanese cuisine is characterized by its subtle and delicate flavors, featuring a combination of salty, sweet, sour, and umami flavors. It also utilizes fresh ingredients with a focus on preserving their natural flavors.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8e368fe-abe0-41a3-b849-3bed48ca6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "            f\"Below is an instruction that describes a task. \"\n",
    "            f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "        )\n",
    "    input_text = (\n",
    "    f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb85c31-a095-41d3-bb07-6e9cd1176a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What are the three primary colors?\n",
      "\n",
      "### Response:\n",
      "The three primary colors are red, blue, and yellow.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[1])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[1]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25869857-bd66-4ea5-92da-d74343725512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 85% 44201\n",
      "Validation set length: 5% 2601\n",
      "Test set length: 10% 5200\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "print(\"Training set length: 85%\", len(train_data))\n",
    "print(\"Validation set length: 5%\", len(val_data))\n",
    "print(\"Test set length: 10%\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaab6e4c-0a89-4597-904a-8394ca7ab646",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "            tokenizer.encode(full_text)\n",
    "            )\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08df747f-2b96-4b6d-b3b6-aef71405702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d9fe12-1365-4542-a9fc-a5287dbe1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    \n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    # print(batch_max_length)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        \n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "        new_item + [pad_token_id] *\n",
    "        (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        # print(\"inputs\",inputs)\n",
    "        inputs_lst.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d98300-fcc3-4081-a030-4b9979160761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "inputs_1,\n",
    "inputs_2,\n",
    "inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79447669-d32f-4f94-854c-8e20bb4af4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 1, 2, 3, 4], [5, 6], [7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b73ed7f9-1905-4374-a18e-40101372a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "\n",
      "\n",
      "targets:  tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    \n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "                )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor\n",
    "\n",
    "    \n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(\"inputs: \",inputs, end=\"\\n\\n\\n\")\n",
    "print(\"targets: \",targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63d6c05-dd3d-4362-b30e-53d799bd5b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "848a2036-ad0c-4f09-ae3c-7d825d5c0c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [5, 6], [7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ec3cd6-68b2-4448-96f9-5c6d5d7a0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(item)+1 for item in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78ec6cff-fc47-4885-8ecf-5d042e77c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =(batch[1] + [456] *2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9089f30-8feb-4cdf-a1f0-f570270993a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 456]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253da417-57e4-449a-be0e-65dc63d8ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab7546c5-e48e-44d3-9411-bb03c9054ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe49a664-579e-445e-97d5-1991d2848219",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_1 = torch.tensor(\n",
    "   [ [-1.0, 1.0],\n",
    "    [-0.5, 1.5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "717f4b7b-987d-487b-a732-be71c4a66f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea5c70ec-edd2-49cc-8b04-0b44c3fff37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0791b319-395e-4e30-ba8c-349ae6470145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "        [[-1.0, 1.0],\n",
    "        [-0.5, 1.5],\n",
    "        [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "775565ef-a230-4e97-84c8-7b4ae2bea564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e1ee3f-5bcb-4fe7-89e7-13fb0aaed14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5514)\n",
      "tensor([[-0.5514, -1.5514, -1.5514],\n",
      "        [-1.5514, -0.5514, -1.5514],\n",
      "        [-1.5514, -1.5514, -0.5514]])\n",
      "tensor([[-0.5514, -1.5514, -1.5514],\n",
      "        [-1.5514, -0.5514, -1.5514],\n",
      "        [-1.5514, -1.5514, -0.5514]])\n",
      "tensor(0.5514)\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1.,0.,0.],\n",
    "                       [0.,1.,0.],\n",
    "                       [0.,0.,1.]])\n",
    "y = torch.LongTensor([0,1,2])\n",
    "\n",
    "print(torch.nn.functional.cross_entropy(x, y))\n",
    "\n",
    "print(F.softmax(x, 1).log())\n",
    "print(F.log_softmax(x, 1))\n",
    "\n",
    "print(F.nll_loss(F.log_softmax(x, 1), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eebefe37-d646-42aa-b80a-e3d25d9f6786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3448c52a-0c53-4c28-8ccb-b7300cb09902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(\n",
    "custom_collate_fn,\n",
    "device=device,\n",
    "allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a142caa-e1a2-4a32-a344-423bc0eccf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "train_dataset,\n",
    "batch_size=batch_size,\n",
    "collate_fn=customized_collate_fn,\n",
    "shuffle=True,\n",
    "drop_last=True,\n",
    "num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "val_dataset,\n",
    "batch_size=batch_size,\n",
    "collate_fn=customized_collate_fn,\n",
    "shuffle=False,\n",
    "drop_last=False,\n",
    "num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "test_dataset,\n",
    "batch_size=batch_size,\n",
    "collate_fn=customized_collate_fn,\n",
    "shuffle=False,\n",
    "drop_last=False,\n",
    "num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f160ea1-8875-4d9c-bdab-c13ee4b97be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.InstructionDataset at 0x72b6b99e4df0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6da2d3ca-d658-4923-b67b-e7d35e715c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([1, 88]) torch.Size([1, 88])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b63aebc-18d8-4d9f-aefe-8373f0566778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39d897c6-99ef-4433-a920-b720321d9158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 15056,   257,  1351,   286,  4736,    11,\n",
       "        36509,  1123,  1748,   355,  2035,   257,  4166,   393,  5922,  1748,\n",
       "           13,   198,   198, 21017, 23412,    25,   198,    50,  5173,  1681,\n",
       "           11, 15338,   390, 42799,    11, 23732,   198,   198, 21017, 18261,\n",
       "           25,   198,    50,  5173,  1681,   318,   257,  4166,  1748,    13,\n",
       "          198,    49,   952,   390, 42799,   318,   257,  5922,  1748,    13,\n",
       "          198,    34, 18131,   318,   257,  5922,  1748,    13],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c0bc01-8e06-445e-9e4c-c3ae5be0b4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 88])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b2811c-f4b7-4d00-9db1-1be22ccb2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = targets[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4432a754-e0dd-4082-b1d6-53b26c2113b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fb4577b-1722-4c46-aaa6-8d3f8e260909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGiven a list of cities, classify each city as either a developed or developing city.\\n\\n### Input:\\nSydney, Rio de Janeiro, Cairo\\n\\n### Response:'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(a[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3ec5acc-261b-4e69-900f-fbe74f384264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow>=2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eca79cfd-7f2a-4f35-b75a-8f624e81fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 06:46:50.521229: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-07 06:46:50.686164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746580610.750111    5226 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746580610.766988    5226 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746580610.897448    5226 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746580610.897467    5226 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746580610.897469    5226 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746580610.897470    5226 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-07 06:46:50.913180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "BASE_CONFIG = {\n",
    "\"vocab_size\": 50257,  # Vocabulary size\n",
    "\"context_length\": 1024, # Context length\n",
    "\"drop_rate\": 0.0, # Dropout rate\n",
    "\"qkv_bias\": True  # Query-key-value bias\n",
    "}\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "# BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "# model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "# settings, params = download_and_load_gpt2(\n",
    "# model_size=model_size,\n",
    "# models_dir=\"gpt2\"\n",
    "# )\n",
    "# model = GPTModel(BASE_CONFIG)\n",
    "# load_weights_into_gpt(model, params)\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15dde02d-da80-46a8-8675-bbd62d2e1ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain how using transitional words help in writing\n",
      "\n",
      "### Input:\n",
      "\"<noinput>\"\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af7c1fd7-75ed-4e7a-bdd7-2c1bb3c1df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_preprocessing.ipynb import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6321c53-b250-494d-9903-a4d6b63d0105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aroop/llm\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "722e7909-b824-4cf3-bf15-34c815efa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b59b0e3a-bb83-4481-bae4-8c182e67ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aroop/llm/notebook\n"
     ]
    }
   ],
   "source": [
    "%cd notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8ce4206-5f29-4dba-b279-0f8f5cc38cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8c63d13-fab9-48ea-a041-a4765bcb29e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ..src.model import GPTModel\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "token_ids = generate(\n",
    "model=model,\n",
    "idx=text_to_token_ids(input_text, tokenizer),\n",
    "max_new_tokens=35,\n",
    "context_size=BASE_CONFIG[\"context_length\"],\n",
    "eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7dd1c54-0d5d-4ff1-9fb2-dbbfb30efbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vul fourth Arche provincialreditation Casting Swe module waive piljsthirst improperondo LV misunderstoodarticlebrowser celeopenshandler charter ReconERY skippingDiv Manor positive Av bows Wilmington Isis EstimatedÙŽ Psal\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7132defe-6fe3-40d9-b9d6-2de2203c6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pasted\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        \n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        return total_loss / num_batches\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        print(idx_cond)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73e4715c-8c6a-4b14-8148-9941d7d4d05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.194048309326172\n",
      "Validation loss: 2.189373779296875\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "val_loss = calc_loss_loader(\n",
    "val_loader, model, device, num_batches=5\n",
    ")\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5f5cf6e-ee84-436f-a8a1-ddb6066dd6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.083, Val loss 2.122\n",
      "Ep 1 (Step 000005): Train loss 1.845, Val loss 1.869\n",
      "Ep 1 (Step 000010): Train loss 1.828, Val loss 1.746\n",
      "Ep 1 (Step 000015): Train loss 1.198, Val loss 1.649\n",
      "Ep 1 (Step 000020): Train loss 1.556, Val loss 1.580\n",
      "Ep 1 (Step 000025): Train loss 1.420, Val loss 1.537\n",
      "Ep 1 (Step 000030): Train loss 1.420, Val loss 1.504\n",
      "Ep 1 (Step 000035): Train loss 1.408, Val loss 1.479\n",
      "Ep 1 (Step 000040): Train loss 1.089, Val loss 1.459\n",
      "Ep 1 (Step 000045): Train loss 0.918, Val loss 1.435\n",
      "Ep 1 (Step 000050): Train loss 0.909, Val loss 1.420\n",
      "Ep 1 (Step 000055): Train loss 1.551, Val loss 1.398\n",
      "Ep 1 (Step 000060): Train loss 1.668, Val loss 1.381\n",
      "Ep 1 (Step 000065): Train loss 1.354, Val loss 1.367\n",
      "Ep 1 (Step 000070): Train loss 1.146, Val loss 1.357\n",
      "Ep 1 (Step 000075): Train loss 0.877, Val loss 1.349\n",
      "Ep 1 (Step 000080): Train loss 1.050, Val loss 1.337\n",
      "Ep 1 (Step 000085): Train loss 0.827, Val loss 1.330\n",
      "Ep 1 (Step 000090): Train loss 0.847, Val loss 1.320\n",
      "Ep 1 (Step 000095): Train loss 1.006, Val loss 1.306\n",
      "Ep 1 (Step 000100): Train loss 1.317, Val loss 1.298\n",
      "Ep 1 (Step 000105): Train loss 1.328, Val loss 1.293\n",
      "Ep 1 (Step 000110): Train loss 0.746, Val loss 1.284\n",
      "Ep 1 (Step 000115): Train loss 1.048, Val loss 1.276\n",
      "Ep 1 (Step 000120): Train loss 0.658, Val loss 1.268\n",
      "Ep 1 (Step 000125): Train loss 1.039, Val loss 1.263\n",
      "Ep 1 (Step 000130): Train loss 1.063, Val loss 1.260\n",
      "Ep 1 (Step 000135): Train loss 0.635, Val loss 1.260\n",
      "Ep 1 (Step 000140): Train loss 0.909, Val loss 1.256\n",
      "Ep 1 (Step 000145): Train loss 1.044, Val loss 1.252\n",
      "Ep 1 (Step 000150): Train loss 1.073, Val loss 1.244\n",
      "Ep 1 (Step 000155): Train loss 0.856, Val loss 1.238\n",
      "Ep 1 (Step 000160): Train loss 0.928, Val loss 1.234\n",
      "Ep 1 (Step 000165): Train loss 1.177, Val loss 1.236\n",
      "Ep 1 (Step 000170): Train loss 0.610, Val loss 1.231\n",
      "Ep 1 (Step 000175): Train loss 1.389, Val loss 1.228\n",
      "Ep 1 (Step 000180): Train loss 1.453, Val loss 1.223\n",
      "Ep 1 (Step 000185): Train loss 1.517, Val loss 1.223\n",
      "Ep 1 (Step 000190): Train loss 0.882, Val loss 1.215\n",
      "Ep 1 (Step 000195): Train loss 0.577, Val loss 1.214\n",
      "Ep 1 (Step 000200): Train loss 0.743, Val loss 1.212\n",
      "Ep 1 (Step 000205): Train loss 1.067, Val loss 1.210\n",
      "Ep 1 (Step 000210): Train loss 0.859, Val loss 1.204\n",
      "Ep 1 (Step 000215): Train loss 1.189, Val loss 1.200\n",
      "Ep 1 (Step 000220): Train loss 0.920, Val loss 1.196\n",
      "Ep 1 (Step 000225): Train loss 1.350, Val loss 1.191\n",
      "Ep 1 (Step 000230): Train loss 1.181, Val loss 1.194\n",
      "Ep 1 (Step 000235): Train loss 0.667, Val loss 1.198\n",
      "Ep 1 (Step 000240): Train loss 1.160, Val loss 1.194\n",
      "Ep 1 (Step 000245): Train loss 1.211, Val loss 1.191\n",
      "Ep 1 (Step 000250): Train loss 0.843, Val loss 1.186\n",
      "Ep 1 (Step 000255): Train loss 0.964, Val loss 1.185\n",
      "Ep 1 (Step 000260): Train loss 1.047, Val loss 1.182\n",
      "Ep 1 (Step 000265): Train loss 0.579, Val loss 1.177\n",
      "Ep 1 (Step 000270): Train loss 0.965, Val loss 1.173\n",
      "Ep 1 (Step 000275): Train loss 0.575, Val loss 1.172\n",
      "Ep 1 (Step 000280): Train loss 1.430, Val loss 1.168\n",
      "Ep 1 (Step 000285): Train loss 0.747, Val loss 1.170\n",
      "Ep 1 (Step 000290): Train loss 0.416, Val loss 1.174\n",
      "Ep 1 (Step 000295): Train loss 0.565, Val loss 1.176\n",
      "Ep 1 (Step 000300): Train loss 1.005, Val loss 1.171\n",
      "Ep 1 (Step 000305): Train loss 0.510, Val loss 1.168\n",
      "Ep 1 (Step 000310): Train loss 1.132, Val loss 1.162\n",
      "Ep 1 (Step 000315): Train loss 0.873, Val loss 1.156\n",
      "Ep 1 (Step 000320): Train loss 1.192, Val loss 1.154\n",
      "Ep 1 (Step 000325): Train loss 1.003, Val loss 1.157\n",
      "Ep 1 (Step 000330): Train loss 0.661, Val loss 1.154\n",
      "Ep 1 (Step 000335): Train loss 1.290, Val loss 1.149\n",
      "Ep 1 (Step 000340): Train loss 0.948, Val loss 1.150\n",
      "Ep 1 (Step 000345): Train loss 1.193, Val loss 1.155\n",
      "Ep 1 (Step 000350): Train loss 1.124, Val loss 1.158\n",
      "Ep 1 (Step 000355): Train loss 1.051, Val loss 1.156\n",
      "Ep 1 (Step 000360): Train loss 0.985, Val loss 1.148\n",
      "Ep 1 (Step 000365): Train loss 1.057, Val loss 1.141\n",
      "Ep 1 (Step 000370): Train loss 1.192, Val loss 1.135\n",
      "Ep 1 (Step 000375): Train loss 0.916, Val loss 1.134\n",
      "Ep 1 (Step 000380): Train loss 1.068, Val loss 1.137\n",
      "Ep 1 (Step 000385): Train loss 0.589, Val loss 1.142\n",
      "Ep 1 (Step 000390): Train loss 0.807, Val loss 1.145\n",
      "Ep 1 (Step 000395): Train loss 1.137, Val loss 1.146\n",
      "Ep 1 (Step 000400): Train loss 1.071, Val loss 1.144\n",
      "Ep 1 (Step 000405): Train loss 0.708, Val loss 1.138\n",
      "Ep 1 (Step 000410): Train loss 0.631, Val loss 1.133\n",
      "Ep 1 (Step 000415): Train loss 1.053, Val loss 1.127\n",
      "Ep 1 (Step 000420): Train loss 0.581, Val loss 1.129\n",
      "Ep 1 (Step 000425): Train loss 0.944, Val loss 1.137\n",
      "Ep 1 (Step 000430): Train loss 0.846, Val loss 1.140\n",
      "Ep 1 (Step 000435): Train loss 0.623, Val loss 1.134\n",
      "Ep 1 (Step 000440): Train loss 0.654, Val loss 1.131\n",
      "Ep 1 (Step 000445): Train loss 1.088, Val loss 1.133\n",
      "Ep 1 (Step 000450): Train loss 0.821, Val loss 1.128\n",
      "Ep 1 (Step 000455): Train loss 0.576, Val loss 1.128\n",
      "Ep 1 (Step 000460): Train loss 0.697, Val loss 1.127\n",
      "Ep 1 (Step 000465): Train loss 1.048, Val loss 1.129\n",
      "Ep 1 (Step 000470): Train loss 0.979, Val loss 1.134\n",
      "Ep 1 (Step 000475): Train loss 0.852, Val loss 1.130\n",
      "Ep 1 (Step 000480): Train loss 0.710, Val loss 1.131\n",
      "Ep 1 (Step 000485): Train loss 0.851, Val loss 1.128\n",
      "Ep 1 (Step 000490): Train loss 0.628, Val loss 1.122\n",
      "Ep 1 (Step 000495): Train loss 0.807, Val loss 1.128\n",
      "Ep 1 (Step 000500): Train loss 1.197, Val loss 1.129\n",
      "Ep 1 (Step 000505): Train loss 0.599, Val loss 1.129\n",
      "Ep 1 (Step 000510): Train loss 1.150, Val loss 1.130\n",
      "Ep 1 (Step 000515): Train loss 0.996, Val loss 1.127\n",
      "Ep 1 (Step 000520): Train loss 1.144, Val loss 1.127\n",
      "Ep 1 (Step 000525): Train loss 0.371, Val loss 1.129\n",
      "Ep 1 (Step 000530): Train loss 1.074, Val loss 1.122\n",
      "Ep 1 (Step 000535): Train loss 0.649, Val loss 1.122\n",
      "Ep 1 (Step 000540): Train loss 1.025, Val loss 1.118\n",
      "Ep 1 (Step 000545): Train loss 0.485, Val loss 1.117\n",
      "Ep 1 (Step 000550): Train loss 0.831, Val loss 1.124\n",
      "Ep 1 (Step 000555): Train loss 1.008, Val loss 1.119\n",
      "Ep 1 (Step 000560): Train loss 0.693, Val loss 1.119\n",
      "Ep 1 (Step 000565): Train loss 1.020, Val loss 1.118\n",
      "Ep 1 (Step 000570): Train loss 1.051, Val loss 1.115\n",
      "Ep 1 (Step 000575): Train loss 1.183, Val loss 1.113\n",
      "Ep 1 (Step 000580): Train loss 1.011, Val loss 1.109\n",
      "Ep 1 (Step 000585): Train loss 0.952, Val loss 1.114\n",
      "Ep 1 (Step 000590): Train loss 1.104, Val loss 1.119\n",
      "Ep 1 (Step 000595): Train loss 1.099, Val loss 1.120\n",
      "Ep 1 (Step 000600): Train loss 0.955, Val loss 1.117\n",
      "Ep 1 (Step 000605): Train loss 0.993, Val loss 1.116\n",
      "Ep 1 (Step 000610): Train loss 1.156, Val loss 1.116\n",
      "Ep 1 (Step 000615): Train loss 0.882, Val loss 1.116\n",
      "Ep 1 (Step 000620): Train loss 0.751, Val loss 1.127\n",
      "Ep 1 (Step 000625): Train loss 0.910, Val loss 1.125\n",
      "Ep 1 (Step 000630): Train loss 0.814, Val loss 1.124\n",
      "Ep 1 (Step 000635): Train loss 0.718, Val loss 1.125\n",
      "Ep 1 (Step 000640): Train loss 0.648, Val loss 1.129\n",
      "Ep 1 (Step 000645): Train loss 1.130, Val loss 1.135\n",
      "Ep 1 (Step 000650): Train loss 0.714, Val loss 1.120\n",
      "Ep 1 (Step 000655): Train loss 1.047, Val loss 1.117\n",
      "Ep 1 (Step 000660): Train loss 1.154, Val loss 1.114\n",
      "Ep 1 (Step 000665): Train loss 1.043, Val loss 1.112\n",
      "Ep 1 (Step 000670): Train loss 0.945, Val loss 1.113\n",
      "Ep 1 (Step 000675): Train loss 0.384, Val loss 1.115\n",
      "Ep 1 (Step 000680): Train loss 1.289, Val loss 1.116\n",
      "Ep 1 (Step 000685): Train loss 0.855, Val loss 1.117\n",
      "Ep 1 (Step 000690): Train loss 0.533, Val loss 1.118\n",
      "Ep 1 (Step 000695): Train loss 0.842, Val loss 1.117\n",
      "Ep 1 (Step 000700): Train loss 0.660, Val loss 1.119\n",
      "Ep 1 (Step 000705): Train loss 1.132, Val loss 1.119\n",
      "Ep 1 (Step 000710): Train loss 0.867, Val loss 1.117\n",
      "Ep 1 (Step 000715): Train loss 0.665, Val loss 1.113\n",
      "Ep 1 (Step 000720): Train loss 1.048, Val loss 1.107\n",
      "Ep 1 (Step 000725): Train loss 1.217, Val loss 1.109\n",
      "Ep 1 (Step 000730): Train loss 1.118, Val loss 1.108\n",
      "Ep 1 (Step 000735): Train loss 0.584, Val loss 1.106\n",
      "Ep 1 (Step 000740): Train loss 0.975, Val loss 1.113\n",
      "Ep 1 (Step 000745): Train loss 0.954, Val loss 1.106\n",
      "Ep 1 (Step 000750): Train loss 0.769, Val loss 1.104\n",
      "Ep 1 (Step 000755): Train loss 1.155, Val loss 1.100\n",
      "Ep 1 (Step 000760): Train loss 0.648, Val loss 1.094\n",
      "Ep 1 (Step 000765): Train loss 0.768, Val loss 1.094\n",
      "Ep 1 (Step 000770): Train loss 0.524, Val loss 1.093\n",
      "Ep 1 (Step 000775): Train loss 1.086, Val loss 1.094\n",
      "Ep 1 (Step 000780): Train loss 0.589, Val loss 1.097\n",
      "Ep 1 (Step 000785): Train loss 1.004, Val loss 1.098\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00005\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 8\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     14\u001b[0m execution_time_minutes \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[0;32mIn[48], line 62\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m     train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     64\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n",
      "Cell \u001b[0;32mIn[48], line 9\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, train_loader, val_loader, device, eval_iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m calc_loss_loader(\n\u001b[1;32m      7\u001b[0m     train_loader, model, device, num_batches\u001b[38;5;241m=\u001b[39meval_iter\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_iter\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss, val_loss\n",
      "Cell \u001b[0;32mIn[48], line 39\u001b[0m, in \u001b[0;36mcalc_loss_loader\u001b[0;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m num_batches:\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m calc_loss_batch(\n\u001b[1;32m     37\u001b[0m     input_batch, target_batch, model, device\n\u001b[1;32m     38\u001b[0m     )\n\u001b[0;32m---> 39\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(\n",
    "model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267b3cb-c478-4ebc-86ce-88d95e7b081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ec6b5-5bb9-4d35-add2-30b7b6a1f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67abd1-754f-456d-b912-73d57a3ff51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:5]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(model=model, idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "            context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "        )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4641a33-db64-4ea6-be20-aeb5b1bd9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "\"model_state_dict\": model.state_dict(),\n",
    "\"optimizer_state_dict\": optimizer.state_dict(),\n",
    "},\n",
    "\"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb2436-dac2-4b59-8c69-79ef4b7fed17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
