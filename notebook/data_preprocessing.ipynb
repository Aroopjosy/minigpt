{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbcbe07-38c8-40e8-ae03-0527ddbf3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "# \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "# \"the-verdict.txt\")\n",
    "# file_path = \"the-verdict.txt\"\n",
    "# urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f203b22f-d3b3-4be5-a0b9-c177ae875e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    print(\"Total number of character:\", len(raw_text))\n",
    "    print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a1e1b6-053c-46c1-86fb-959fe0b1a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fb907d-82b2-445a-b4f2-2b78bcdd885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f943c4-3834-4136-a4e8-762a12fb9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d734e2-26cd-4f68-b4bf-8f073ae8ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb549a58-0fb9-479c-a11f-2e7605ccffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81f7617-a537-496e-af80-319284759c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e74a210-0116-46db-bfc7-ec45cc5ea3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa68121-9bbe-4105-959f-ad1814e3a913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon-dancers', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'They', 'This', 'Those', 'Though']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7149aef-b69b-4b7c-bf13-db6bcac582a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ee371c-36ef-4ef0-b638-84f387686d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer class \n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "        item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a908e3-b569-4c67-853c-e0a798b1aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a41e05-3f0f-4051-9306-875958e56978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee162a9-8012-4a2c-8d38-bfd850600481",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "# print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1e398a-97a6-495b-871e-8ce670db6a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c64bbca-62f7-44a1-a414-02cd360db0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9df98237-c066-42a2-81f1-26ba4f9efeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "        item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        preprocessed = [item if item in self.str_to_int\n",
    "        else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0138f130-d443-4bf7-a25a-25f74b4b520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70a9f237-ceae-48e5-bec7-3afb2328e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "816d1d09-0c81-471e-9f2d-8dfeadca6f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a859fbba-3d8c-4831-be21-6188dfedead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fa31400-d075-436d-87e7-42402b0ab7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tiktoken.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d096a04-3eea-4102-b7db-7572342b4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cf948ba-1ef1-4d7b-aae2-a25ab2ba12cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "\"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e0d0c6-93aa-4501-b33d-c58f31e0786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e3d9d86-f2d8-4023-af68-9d60375650ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad3d1331-b55d-4007-8914-064a01f08e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2d97cb-fa5c-4fc1-b56b-2f7652cbcfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138, 257, 7026, 15632, 438, 2016, 257, 922, 5891, 1576, 438, 568, 340, 373, 645, 1049, 5975, 284, 502, 284, 3285, 326, 11, 287, 262, 6001, 286, 465, 13476, 11, 339, 550, 5710, 465, 12036, 11, 6405, 257, 5527, 27075, 11]\n"
     ]
    }
   ],
   "source": [
    "print(enc_text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e75de4c6-e8bd-4dc1-891c-59cba800f134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow,'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(enc_text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "896c7b3d-4508-4512-9af2-5cdbaad613e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f5ca120-df7b-4b3d-8007-794208f8cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id in range(1, context_size+1):\n",
    "#     x = enc_sample[:id]\n",
    "#     y = enc_sample[id]\n",
    "#     print(f\"x = {x} y = {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85e83c3c-7d16-4945-ac42-28e5657194ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e11b730-73be-49f3-8724-1c06417a242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "add579af-f2e7-4f82-81fa-94f2114afc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d6de6a0-1ef7-4c03-bf8c-fa1fd9e904b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "    stride=128, shuffle=True, drop_last=True,\n",
    "    num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    drop_last=drop_last,\n",
    "    num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a02c23a5-8036-43ee-b878-dae88152116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "dataloader = create_dataloader_v1(\n",
    "raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b851925b-4890-48e7-8309-97485ec807fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "print(next(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58c6df7c-e8d9-4343-9a1b-20d7848b7bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "raw_text, batch_size=8, max_length=4, stride=4,\n",
    "shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a35f55a-e804-4738-9c31-8fb97afebd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d09ddd4-f74d-4d27-8155-f8026c5062dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2882484-6bac-42c6-9b01-ec387523aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be6740dc-0159-4148-8f13-11e19a2d321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f07dac5a-b354-4d3f-8404-432eb30c5b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "raw_text, batch_size=8, max_length=max_length,\n",
    "stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe9986a9-8a38-45a9-8f6a-633ec341ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b988d34-f66f-4853-a0e7-20e2ab8ac450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1780b36-4e29-4d51-a7a5-8747ca7c58bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
      "        [ 0.4481,  0.2536, -0.2655,  ...,  0.4997, -1.1991, -1.1844],\n",
      "        [-0.2507, -0.0546,  0.6687,  ...,  0.9618,  2.3737, -0.0528],\n",
      "        [ 0.9457,  0.8657,  1.6191,  ..., -0.4544, -0.7460,  0.3483]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3683671-c7ab-4c80-8c39-cc789b6bedb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2097e03f-1806-4277-b984-946ae81660d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # Your\n",
    "[0.55, 0.87, 0.66], # journey\n",
    "[0.57, 0.85, 0.64], # starts\n",
    "[0.22, 0.58, 0.33], # with\n",
    "[0.77, 0.25, 0.10], # one\n",
    "[0.05, 0.80, 0.55]] # step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8d647db-2cf5-4d21-b658-b05a9675d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91ef3dce-659f-4ca7-b495-0e1c3320f8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f07dd33-48b8-4186-a988-781e6b57d7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2cf476b-054b-40b0-8431-8e51db0637f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57417b34-1bd5-46f9-a7a7-5e6bb3fb2d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5481b266-77d0-4565-8ab5-6fc66353ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[2]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5068c0cc-4a32-4ec2-bb5f-340610408e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d71a30e-7d0d-4379-9373-5785e7a588b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a93589e2-5ed5-43d6-bbb2-63247ef10ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa8c8fe6-1c82-4c41-9773-9c7a478dba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"Row 2 sum:\", row_2_sum)\n",
    "print(\"All row sums:\", attn_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beb68526-478b-4504-adbc-1aa2bda57b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "025c828a-44cb-40e1-924b-28d599229d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05f18706-2c66-4046-884e-218825c328be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous 2nd context vector:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2e63e8e-ada0-4f22-88fa-03750d46ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key= torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ea8115f-96f2-48ee-95d5-485dcfff4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "679644c4-f313-4e9a-8b84-028e96c5ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a73b478e-b140-446f-841b-5fd9540c037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d447a24-611e-4b99-997f-fbe3f07a9c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d5feab5-83d0-4b8b-babb-7bd454fbbcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "104a2818-d391-4abf-8e1c-6f0201276c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d3a7680-a613-4018-86cb-bd43eda54a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b2cd115-6ba2-4e34-aa5c-62dd16825bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self attention snippet \n",
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6c03936f-9a7d-4a17-a670-4c8b398f0bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9ece663-b541-4f0d-8cb6-f96063ff8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd modified self attention class \n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d361513b-e83e-4df2-b535-5c51c9314950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "527ca72a-9e16-4484-b058-968d535c2454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5b4a2e3-606d-40c9-b7dd-f096620ee02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "099857c6-8627-4b61-883c-07ff9884bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights*mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d92f0f6b-a18e-48b6-8d40-f8e49273b589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cda38513-fe9c-4afc-8fd8-ac3974a725ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "print(mask)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7eb20448-d663-4aa2-8126-112064c5957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58538a84-6ce1-4715-85ce-41cee81ad7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f69362f2-e3bb-4581-b46c-fbc8f913899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94fb4b79-6562-475b-9d5e-0ccf7c92197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9036494-ae97-47b1-8762-a3fc8ad1d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self attention class with causual attention code\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "    dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "        'mask',\n",
    "        torch.triu(torch.ones(context_length, context_length),diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores.masked_fill_(\n",
    "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fea2b5e6-d73a-42ca-9ed2-5802896d741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75ad3835-31d0-47ca-ab99-0868a9f11e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "        dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "        [CausalAttention(\n",
    "        d_in, d_out, context_length, dropout, qkv_bias\n",
    "        )\n",
    "        for _ in range(num_heads)]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41f0b6fa-93ea-44da-829a-d8b2252feffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81dd5ee6-6ac5-41ee-bbac-1b03ccb0f56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "mha = MultiHeadAttentionWrapper(\n",
    "d_in, d_out, context_length, 0.0, num_heads=2\n",
    ")\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff06a7e-1b60-41f0-b3f1-fe06b7fd1907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8352/3570142945.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import torch.nn as nn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     def __init__(self, d_in, d_out,\n\u001b[1;32m      5\u001b[0m         context_length, dropout, num_heads, qkv_bias=False):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out,\n",
    "        context_length, dropout, num_heads, qkv_bias=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "        \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "        \"mask\",\n",
    "        torch.triu(torch.ones(context_length, context_length),\n",
    "        diagonal=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        \n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(\n",
    "        b, num_tokens, self.d_out\n",
    "        )\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ef4ec1b-7828-4010-bb2c-03a78e496973",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "                   \n",
    "                    [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8022449-b6b4-4583-92df-d977499ba3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1be3a80-fe6c-44f6-89a6-96ad89ae5bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.3208, 1.1631, 1.2879],\n",
      "          [1.1631, 2.2150, 1.8424],\n",
      "          [1.2879, 1.8424, 2.0402]],\n",
      "\n",
      "         [[0.4391, 0.7003, 0.5903],\n",
      "          [0.7003, 1.3737, 1.0620],\n",
      "          [0.5903, 1.0620, 0.9912]]]])\n"
     ]
    }
   ],
   "source": [
    "print(a @ a.transpose(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c04be45c-5a01-4433-89df-b337d27356b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First head:\n",
      " tensor([[1.3208, 1.1631, 1.2879],\n",
      "        [1.1631, 2.2150, 1.8424],\n",
      "        [1.2879, 1.8424, 2.0402]])\n",
      "\n",
      "Second head:\n",
      " tensor([[0.4391, 0.7003, 0.5903],\n",
      "        [0.7003, 1.3737, 1.0620],\n",
      "        [0.5903, 1.0620, 0.9912]])\n"
     ]
    }
   ],
   "source": [
    "first_head = a[0, 0, :, :]\n",
    "first_res = first_head @ first_head.T\n",
    "print(\"First head:\\n\", first_res)\n",
    "second_head = a[0, 1, :, :]\n",
    "second_res = second_head @ second_head.T\n",
    "print(\"\\nSecond head:\\n\", second_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d65a87df-b768-4ec0-b2c6-23f39b2d0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17457cec-5a8a-478a-a964-adf54f498272",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "deac1804-d23d-4221-8f74-15332ca8baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 code \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "                    *[DummyTransformerBlock(cfg)\n",
    "                    for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "        torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        \n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1f6b805-9a2a-42da-a82a-0753f8b86037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dff06e4a-181e-4fc2-9581-17a99c91c032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.6442,  0.4002, -0.6301,  ..., -1.7908,  1.7656,  0.7682],\n",
      "         [ 0.4882, -1.3109, -1.0632,  ..., -0.3465,  0.5326, -0.2410],\n",
      "         [-0.2399,  1.1010,  0.5612,  ..., -0.1098, -0.0362, -1.2148],\n",
      "         [-1.0398, -0.0377,  1.6094,  ..., -1.7665, -1.2933, -1.6788]],\n",
      "\n",
      "        [[ 0.9140,  0.5402, -0.9668,  ..., -1.1724,  1.3664,  0.5812],\n",
      "         [-0.5798, -0.3736, -1.2043,  ..., -1.7816,  0.4513,  0.0474],\n",
      "         [ 0.1278, -0.4755, -0.8627,  ..., -0.6784,  0.1200, -0.3627],\n",
      "         [-1.0198,  1.5377,  1.0421,  ..., -0.9028, -0.9430, -0.5627]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5347bba7-608d-49bd-ad79-4d98df02f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "73f32418-be45-4f9b-bbac-969a7f562420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape : torch.Size([2, 5])\n",
      "batch data : tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
      "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])\n"
     ]
    }
   ],
   "source": [
    "print('batch shape :', batch_example.shape)\n",
    "print('batch data :', batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8be0f394-e412-42e5-8f7e-2a4fc57cb083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=6, bias=True)\n",
       "  (1): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fde7dab1-8bed-4f4f-bf10-bd6cb7dab4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1324, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out[0]) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "800b999e-ea1a-463b-b054-15505952b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b5fef2a-aa4d-4c40-b1c7-cdf9a890b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0020a632-a4da-499a-a29e-7a5319f1e3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9aa07fd5-902b-4ec6-a687-bafd577169fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81c29b51-52c5-41d7-baaf-128b7c3bbcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23922f11-649d-4788-b4ce-db6ac578705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "        (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c98390fe-2c16-4b9f-b7e4-f95b8ebb6df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7ded1b6-33ac-43b6-83f2-9d210afb9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "        GELU(),\n",
    "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fed5705-79a1-4891-bf14-de57069fa30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 0],\n",
       "        [5, 0, 5]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(10, (2,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e899d21-958c-413d-b8a5-d80d12966a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d6282c7-977b-4bce-8bea-098f2f6cba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "604601aa-878a-4a33-a7f5-4a243990828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ae6eb60a-7edd-450d-a5b4-9c991cff234b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1119d2aa-2a8b-46e1-b665-59c4d3fe8098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
       "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "660e4e25-9120-42de-89bb-f770cd01627d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c669d25b-401e-4623-9e82-1fd881f12a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "                    nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "                        GELU()),\n",
    "                        nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
    "                        GELU()),\n",
    "                        nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),\n",
    "                        GELU()),\n",
    "                        nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),\n",
    "                        GELU()),\n",
    "                        nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
    "                        GELU())\n",
    "                        ])        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "37631503-0caa-4e93-9085-0db548908e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "                            layer_sizes, use_shortcut=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5912ce3-9c1e-40f8-ae31-a15eab390e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        # print(param)\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0ab77255-0b36-4e05-a334-88770f84a7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f73d0edf-67a2-4846-990a-382e507b3d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694108307361603\n",
      "layers.2.0.weight has gradient mean of 0.3289699852466583\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ffdffb49-77e3-4d70-aaf4-431673b2eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "        d_in=cfg[\"emb_dim\"],\n",
    "        d_out=cfg[\"emb_dim\"],\n",
    "        context_length=cfg[\"context_length\"],\n",
    "        num_heads=cfg[\"n_heads\"],\n",
    "        dropout=cfg[\"drop_rate\"],\n",
    "        qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "342ae07c-4862-4a6c-ac92-88457f132c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc8c81ef-5b4a-4c87-bc65-53d3ab2d2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 model\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "22ced93e-7cac-41a5-8169-3e8be903451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-0.4708,  0.5737, -0.5967,  ...,  0.2019, -0.5665,  0.1800],\n",
      "         [-0.3895, -0.1978, -0.8885,  ...,  0.2242, -1.2341,  0.1752],\n",
      "         [ 0.6973, -0.3432, -0.6080,  ...,  0.3747, -0.6967,  0.1088],\n",
      "         [-0.2962, -0.6957, -1.1371,  ...,  0.3579,  0.3058, -0.2915]],\n",
      "\n",
      "        [[-0.1514,  0.3329, -0.9740,  ..., -0.1368, -0.6974, -0.1851],\n",
      "         [-0.4894, -0.3492, -0.9759,  ...,  0.2951, -0.3396,  0.2109],\n",
      "         [ 0.5082, -0.1425,  0.2549,  ...,  0.1618,  0.1304, -0.3092],\n",
      "         [-0.4146, -0.0514, -0.5187,  ..., -0.1869, -0.1303, -0.4969]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f773c309-373d-4f0f-8c2b-8dff6b87e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 162,419,712\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "77f192b1-8fb1-4b17-bbbe-1d35941fa65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x74680c18fe60>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9de5dc7-6e68-42c9-9757-6d562ce1bc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d665de43-6ec7-4456-a04c-820c29ef03f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 123,822,336\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "total_params - sum(p.numel()\n",
    "for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of trainable parameters \"\n",
    "f\"considering weight tying: {total_params_gpt2:,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b282846d-c721-4303-ab4f-48417b5e0feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 619.58 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "54f31366-d603-4139-9b32-dc198cd90c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        print(idx_cond)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0c05a2d6-0a3e-436a-865e-05e8dec391ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "tensor([[15496,    11,   314,   716]])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "print(encoded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b29368d-e050-4d78-81d4-c28efde1deae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   314,   716]])\n",
      "tensor([[15496,    11,   314,   716, 13240]])\n",
      "tensor([[15496,    11,   314,   716, 13240, 11381]])\n",
      "tensor([[15496,    11,   314,   716, 13240, 11381,  4307]])\n",
      "tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640]])\n",
      "tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620]])\n",
      "Output: tensor([[15496,    11,   314,   716, 13240, 11381,  4307,  7640, 16620, 34991]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "077b689b-2ff2-4ef5-a4b0-0375399a8aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Laur inhab DistrinetalkQueue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4d9e07cd-d715-4925-850f-141e6744ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "666b18a7-a127-4fb7-a7a0-946ab512a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ffc95ee7-885e-4d41-8276-e6680dc30890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7acfd494-d46c-4682-bd09-81f305b128b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0506f123-bad1-4445-adeb-ddb2bec0c595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398]])\n",
      "tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174]])\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(start_context, tokenizer),\n",
    "max_new_tokens=10,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e51597e3-2243-402b-9a4e-d2b9e742913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],  # [\"every effort moves\",\n",
    "                        [40, 1107, 588]])   # \"I really like\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "51f4f510-63a1-47ec-b045-898c5fabef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ],   # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])   # \" really like chocolate\"]\n",
    "                                    \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c80c9814-c54b-4040-b26e-6c8b64312ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "tensor([[    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0000,\n",
      "             0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0000,\n",
      "             0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0000,\n",
      "             0.0000]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n",
    "print(probas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "462178d1-917a-4d9e-85cb-eb5bfa49f5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8804536a-b617-47f0-a2c0-f4f501c9fb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(    0.0000)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0][1][39619] #non zero value predicted token probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d33b2c5a-accd-4654-9d14-ae25f1494e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(    0.0000)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expected or targeted token probas\n",
    "probas[0][1][6100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f8a57755-909f-4f1c-82b7-d00ddf1097ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1284b657-98b2-4d01-aab6-c4b8a23b7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 2:  really like chocolate\n",
      "Outputs batch 2:  pressuring empoweredfaith\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2:\"\n",
    "f\" {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ca0d502-4841-4395-a09d-48947d34dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16657],\n",
       "        [  339],\n",
       "        [42826]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec1c97fe-4228-47c4-98fb-1a782a53a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16657,   339, 42826])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[0].squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc53517b-f300-46dc-ba78-2b273eb631dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16657,   339, 42826])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "93d639e7-b7e6-4de6-ac14-d94602fdb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "# torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aff27526-99cc-4167-99a2-23c595a2665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0000,\n",
       "             0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0000,\n",
       "             0.0000],\n",
       "        [    0.0000,     0.0000,     0.0000,  ...,     0.0000,     0.0001,\n",
       "             0.0000]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[text_idx, [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d2461-bd67-416b-a04f-23c8a300ea98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dbcc3a3c-c1cf-4b19-aef3-6856cca7b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "563aee42-eb0a-48a9-a1e8-6079bd6f9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0001,     0.0000,     0.0000,     0.0000,     0.0001,     0.0000])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((target_probas_1, target_probas_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ae581f0c-7fbe-43b2-a814-142639b3228b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "38f71c3f-ae4c-46f9-9330-914279e40708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3d6bad0c-f123-459b-877a-eebbda7ba3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "384ce06e-b35f-4b53-9836-1c02be47a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "16832349-84f4-4b84-9062-fb6d37f61ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "810b4e45-c282-47ed-8d6f-424f5f85a608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b78b79f6-0dd1-4f86-aae5-71644fa51f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.flatten(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e0463610-754f-4c31-88b0-ee669d7e7306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4862)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat[0][3626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b18960ea-e564-4e84-9acf-120069919b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3626,  6100,   345,  1107,   588, 11311])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "75e5ded0-6258-4b9b-8d66-c3e2065666c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a4af137d-f5d9-4741-954c-ee5d40c98aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = torch.tensor([\n",
    "    [[0.1, 0.2, 0.7], [0.3, 0.5, 0.2], [0.4, 0.1, 0.5]],  # batch 0\n",
    "    [[0.8, 0.1, 0.1], [0.2, 0.6, 0.2], [0.5, 0.2, 0.3]]   # batch 1\n",
    "])  # Shape: (2, 3, 3) -> (batch_size=2, num_classes=3, seq_len=3)\n",
    "\n",
    "targets = torch.tensor([\n",
    "    [2, 1, 0],  # batch 0 (true labels at each step)\n",
    "    [1, 2, 0]   # batch 1\n",
    "])\n",
    "\n",
    "text_idx = [0, 1]  # Select both batch samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "38077e66-53a6-4255-b3b1-aaf1a48da2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7000, 0.5000, 0.4000])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0, [0, 1,2], targets[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d7709942-0d75-443c-88e2-46efc7e6d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "069449cb-4e09-4ebc-954f-ce3bc6b2bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5535faf6-be8d-4d2a-9661-781b0089cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f62250b4-f67b-436c-a593-4eb213148e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18431, 2048)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86aea23-ac28-4f7d-8fab-7ca353e6db88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5b2ef5ec-9cf9-42fc-b79a-7b36bd84c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "                train_data,\n",
    "                batch_size=2,\n",
    "                max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                drop_last=True,\n",
    "                shuffle=True,\n",
    "                num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "                val_data,\n",
    "                batch_size=2,\n",
    "                max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                drop_last=False,\n",
    "                shuffle=False,\n",
    "                num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3c6d89f4-0657-4e20-9a02-b4cb39d29442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "225a360a-da90-48a5-83a4-3972544fb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the first batch\n",
    "# for batch in train_loader:\n",
    "#     input_data, target_data = batch  # Unpack the batch\n",
    "#     print(\"Input:\\n\", input_data)\n",
    "#     print(\"Target:\\n\", target_data)\n",
    "#     break  # Stop after the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f63773a8-b1c0-4cc2-9601-a67650a868ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x74680c2cb5c0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e6e154d1-6cea-411b-9548-3fc10713db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "    logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "25f1c2c7-abd2-4a5c-a17e-7261eebcf0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.flatten(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "105e1314-0d20-42f1-b26b-411dd8ebdae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        \n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "        return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "07c6f4a6-e263-43ad-a573-b2a3367c85f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.2197306950887044\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d5f978d0-1418-4099-aa9d-891f0160a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "06ef0f50-903f-4917-88b0-6a5170dbb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cff0b263-fb21-4a19-839a-3cd7730973d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d488a739-52f0-465c-b894-5726e5026edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.966, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 1.627, Val loss 8.335\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,   11,   11,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   13,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 1.354, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 1.299, Val loss 6.573\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290,\n",
      "           11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290,\n",
      "           11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290,\n",
      "           11,   11,   11,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,   11,   11,  290,   11,  290,   11,\n",
      "           11,   11,   11,   11,  290,   11,  290,   11,   11,   11,   11,   11,\n",
      "           11,   11,   11,   11,   11,   11,   11,   11,   11,  290,   11,   11,\n",
      "           11,   11,  290,   11,   11,  290,   11,   11,   11,   11,   11,  290,\n",
      "           11,   11,   11,   11,   11]])\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 1.116, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 0.946, Val loss 6.387\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286,  262,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286,  262,  286,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286,  262,  286,  262,  338]])\n",
      "tensor([[6109, 3626, 6100,  345,   11,  290,  284,  262, 4286,   13,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,  198,  198,    1,   40,   11,  290,\n",
      "          262,  286,  262,  286,  262,  338,  262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290,   314]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290,   314,   550]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290,   314,   550,\n",
      "           587]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290,   314,   550,\n",
      "           587,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,    11,   290,   284,   262,  4286,    13,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,     1,    40,    11,   290,   262,   286,   262,   286,\n",
      "           262,   338,   262, 15393,    11,   290,    11,   290,   314,   550,\n",
      "           587,    11,   290]])\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 1.057, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 0.771, Val loss 6.258\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290,\n",
      "          314]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290,\n",
      "          314,  550]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290,\n",
      "          314,  550,  587]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290,\n",
      "          314,  550,  587,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  286,  262,  284,  262, 4286,  438,  292,  286,\n",
      "          262, 4286,  438,  292,  314,  550,  587,  366,  340,  373,  465,  366,\n",
      "          314,  373,  262,  198,  198,  198,  198,  198,    1,   40,  373,  465,\n",
      "          314,  550,  587,  262,  465, 5986,  438,  392,  340,  262, 4286,  290,\n",
      "          314,  550,  587,  262, 4286]])\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 0.733, Val loss 6.196\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,  760]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257,\n",
      "         1310]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257,\n",
      "         1310,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257,\n",
      "         1310,  262,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257,\n",
      "         1310,  262,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  262,  198,    1, 5812,   11,  290,  339,\n",
      "          373,  407,  262, 1109,  416,  465,  938, 1573,   13,  198,  198,  198,\n",
      "          198,  198,  198,  198,  198,  198,    1,   40,  373,   13,  198,  198,\n",
      "          198,  198,  198,  198,    1, 5812,   11,  314, 2936,  257, 1310,  257,\n",
      "         1310,  262,  198,  198,  198]])\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 0.720, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 0.477, Val loss 6.112\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,  760]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,   26]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,   26,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,   26,  290,  616]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,    26,   290,   616, 13674,    11,\n",
      "           290,   339,   373,   407,   262,  1109,   351,   257,  1310,   286,\n",
      "           262,  2156,   286,   262,  1109,   286,   262,  1109,    11,   290,\n",
      "            13,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198,   198,   198,   198,   198,   198,   198,   198,\n",
      "           198,   198,   198]])\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 0.467, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 0.539, Val loss 6.179\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345,  760]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11,  290,  314]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11,  290,  314, 2936]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11,  290,  314, 2936,  683]])\n",
      "tensor([[6109, 3626, 6100,  345,  760,  553,  373,  530,  286,  262, 4286,  329,\n",
      "         2147,  438,   40, 1297, 9074,   13,  198,  198,    1,   40, 3114,  438,\n",
      "          292,  286,  262, 1109,   11,  290,  314, 2936,  683,  438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62,   438, 13893]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62,   438, 13893,\n",
      "           339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62,   438, 13893,\n",
      "           339,   550]])\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   553,   373,   530,   286,   262,\n",
      "          4286,   329,  2147,   438,    40,  1297,  9074,    13,   198,   198,\n",
      "             1,    40,  3114,   438,   292,   286,   262,  1109,    11,   290,\n",
      "           314,  2936,   683,   438, 14363,   736,   465,  1182,   284,   262,\n",
      "         50085,    13,   198,     1,  5812,    11,   290,    62,   438, 13893,\n",
      "           339,   550,  1464]])\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 0.319, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 0.269, Val loss 6.178\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114,  510]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114,  510,\n",
      "           11]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114,  510,\n",
      "           11,  290]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114,  510,\n",
      "           11,  290, 1816]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,    1,   40, 1422,  470, 6842,  262,\n",
      "         4286,  438,   40, 1297,  502,   13,  198,  198,    1,   40, 3114,  510,\n",
      "           11,  290, 1816,  319]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62,   438, 13893]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62,   438, 13893,\n",
      "           339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62,   438, 13893,\n",
      "           339,   373]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,     1,    40,  1422,   470,\n",
      "          6842,   262,  4286,   438,    40,  1297,   502,    13,   198,   198,\n",
      "             1,    40,  3114,   510,    11,   290,  1816,   319, 39136,   278,\n",
      "           290,  9074,    13,   314,   373,   736,   262,  1182,   284,   804,\n",
      "           510,   379,   262, 15393,   852,  4808,  3810,    62,   438, 13893,\n",
      "           339,   373,   618]])\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 0.220, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.134, Val loss 6.281\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297,  438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366,  1858]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366,  1858,\n",
      "           547]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366,  1858,\n",
      "           547,  1528]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   804,\n",
      "           510,   379,   262, 17548,   286,   262, 50085,    13,   366,  1858,\n",
      "           547,  1528,   618]])\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.106, Val loss 6.325\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297,  438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290,   866]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290,   866,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290,   866,   262,\n",
      "          2119]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290,   866,   262,\n",
      "          2119,    11]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198,   198,  1544,\n",
      "         13818,   757,    11,   290,  9617,   736,   465,  1182,   284,   262,\n",
      "         50085,   757,    13,   314,  2497,   326,    11,   290,   866,   262,\n",
      "          2119,    11,   618]])\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "model.parameters(),\n",
    "lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "836d7008-31d5-4aa5-bee2-314889339430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8f98ab0f-fd61-472d-a2a3-9e3c7d703ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bd01b2c7-621a-4a8f-9b5c-79a0398dfd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297,  438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198]])\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "max_new_tokens=25,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "236afe74-9562-4d3a-8f90-50a384e2fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297]])\n",
      "tensor([[6109, 3626, 6100,  345, 1701,  198,  198,    1, 5297,  438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474]])\n",
      "tensor([[ 6109,  3626,  6100,   345,  1701,   198,   198,     1,  5297,   438,\n",
      "         37121,  1035, 27339,   284,   262, 21296,    13,  1375,  2227,   683,\n",
      "         29178,  3474,   438,   392,   416,   502,  2474,   198]])\n",
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "model=model,\n",
    "idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "max_new_tokens=25,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7c556d33-94c6-4c60-8c5e-68a1db88ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "\"closer\": 0,\n",
    "\"every\": 1,\n",
    "\"effort\": 2,\n",
    "\"forward\": 3,\n",
    "\"inches\": 4,\n",
    "\"moves\": 5,\n",
    "\"pizza\": 6,\n",
    "\"toward\": 7,\n",
    "\"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3f812acc-aab0-4a93-8892-a9f0469566f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'closer',\n",
       " 1: 'every',\n",
       " 2: 'effort',\n",
       " 3: 'forward',\n",
       " 4: 'inches',\n",
       " 5: 'moves',\n",
       " 6: 'pizza',\n",
       " 7: 'toward',\n",
       " 8: 'you'}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "996fe3d9-06d5-4cf3-bf21-3382d81f1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d0e2d042-6f5d-4f23-a30e-83230043813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c594ce0e-ca4c-4853-bb3a-b97a99c60266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0609,     0.0016,     0.0001,     0.5721,     0.0034,     0.0001,\n",
       "            0.0001,     0.3576,     0.0040])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2c31b9fa-8b12-4356-b4cf-c658b8142572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "acd30f69-5ab8-4886-a100-8dec047ad6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "713c0bed-f36d-47fe-8ee7-f1eb63236818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "44ca8fc0-0b70-4cac-a0a6-8a4b9432fe2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1dca97af-417e-4b1a-a366-86c0fef03837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "36cda552-4447-4e90-8a78-5d8565704afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
       "         1.7900])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3a3a172b-5d1d-4e24-951d-872dd8bf4e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "condition=next_token_logits < top_logits[-1],\n",
    "input=torch.tensor(float('-inf')),\n",
    "other=next_token_logits\n",
    ")\n",
    "print(new_logits)\n",
    "# print(new_logits[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8981d8f7-779d-4131-9fce-b2e4036bb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3e5eb536-9ed9-4cb6-b8e0-1a78752571b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fc75cf61-3503-4350-af7d-e1cecc409633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "model=model,\n",
    "idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "max_new_tokens=15,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "top_k=25,\n",
    "temperature=1.4\n",
    ")\n",
    "print(GPT_CONFIG_124M['context_length'])\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "84c03988-2851-45a6-856e-2451372bb2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_token_ids(token_ids_to_text(token_ids, tokenizer), tokenizer).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "946baef4-3c61-4417-8012-5591ce35bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a66f72bd-7080-4311-81f5-2e22f999125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"../model/model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "226f156e-d999-47be-88dd-5a8895f95d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "\"model_state_dict\": model.state_dict(),\n",
    "\"optimizer_state_dict\": optimizer.state_dict(),\n",
    "},\n",
    "\"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b713ac8f-df20-4f32-902e-bf31c623c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9825cc-f659-4e74-98c4-9236cd0c5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow>=2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c3478dc8-fb97-469c-9bc6-d4e5fb350505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# url = (\n",
    "# \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    "# )\n",
    "# filename = url.split('/')[-1]\n",
    "# urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7e8bfd49-945e-4b04-9ede-d7aea120d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# file_name = \"gpt2-small-124M.pth\"\n",
    "# # file_name = \"gpt2-medium-355M.pth\"\n",
    "# # file_name = \"gpt2-large-774M.pth\"\n",
    "# # file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "# url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "# if not os.path.exists(file_name):\n",
    "#     urllib.request.urlretrieve(url, file_name)\n",
    "#     print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "# gpt = GPTModel(BASE_CONFIG)\n",
    "# gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "# gpt.eval()\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# gpt.to(device);\n",
    "\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# token_ids = generate(\n",
    "#     model=gpt,\n",
    "#     idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "#     max_new_tokens=25,\n",
    "#     context_size=NEW_CONFIG[\"context_length\"],\n",
    "#     top_k=50,\n",
    "#     temperature=1.5\n",
    "# )\n",
    "\n",
    "# print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7c016fa2-791b-43fa-a42c-27f91cc778d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Settings:\", settings)\n",
    "# print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fab65-0df9-467f-92e0-2e575f518710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3c956-58f7-4c08-af54-95c044369378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5047cd-3c53-4474-b70a-56496866e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca89e5-f8fe-46b6-acb1-3714066072e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['wpe'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78b62c-78e9-49fb-b79b-2696a2ccd61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params['blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af60d37-d512-41af-9b30-e17d64bc750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f0b64-9f1e-436e-b9bb-1f1278f92afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['g'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da9dc6-2d76-4492-b80b-772dcd96a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ba793-7876-45f0-8c48-717183e1d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9657c94-7a3d-400e-b895-9e30d052bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9a026-5135-4c76-be02-edb3538de847",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NEW_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c146f04-b953-46c4-83ab-2d2753390a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df22cc-3a5a-42c3-8256-f1e57d25becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff849d82-848d-477f-9f59-a80084a5bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fe20c-7631-49bc-9b4b-2e9f5bd0fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "        \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef271a00-82bc-41bc-b1c3-7b6cb7a0c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained weights\n",
    "\n",
    "import numpy as np\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "        gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "        gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "        gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "        gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "        gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "        gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "        gpt.trf_blocks[b].att.out_proj.weight,\n",
    "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "        gpt.trf_blocks[b].att.out_proj.bias,\n",
    "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "        gpt.trf_blocks[b].norm1.scale,\n",
    "        params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "        gpt.trf_blocks[b].norm1.shift,\n",
    "        params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "        gpt.trf_blocks[b].norm2.scale,\n",
    "        params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "        gpt.trf_blocks[b].norm2.shift,\n",
    "        params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f3e71-cf7d-4d17-829f-9e1ab5836f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ec649-7ab9-4210-9069-5053d7b4a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "model=gpt,\n",
    "idx=text_to_token_ids(\"every thing is moving perfect\", tokenizer).to(device),\n",
    "max_new_tokens=25,\n",
    "context_size=NEW_CONFIG[\"context_length\"],\n",
    "top_k=50,\n",
    "temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bebd62-7eaa-4282-95a3-e01e94bca223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
